##Script de DAG para Desafio do Fast Track edição Set/2021
##Desafio PagSeguro

# IMPORTS
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime
import pandas as pd
import numpy as np
from datetime import date, datetime
from kaggle.api.kaggle_api_extended import KaggleApi
import zipfile

def importar_dataset():
    # Importação dos dados e descompactação
    api = KaggleApi()
    api.authenticate()
    api.dataset_download_file('ealaxi/banksim1', file_name='bs140513_032310.csv', force=False)

    with zipfile.ZipFile('bs140513_032310.csv.zip', 'r') as zipref:
        zipref.extractall()

def criar_df():
    return pd.read_csv('bs140513_032310.csv.zip', delimiter=',', quotechar="'", index_col=False)
    
def limpeza_dados(df):
    # Transforma data type da coluna age em int
    df["age"].mask(df["age"]=='U', 0, inplace=True)
    df["age"]=df["age"].astype('int')

    # Limpa coluna gender para somente M e F ou None
    df["gender"].where((df["gender"]=="M") | (df["gender"]=="F"), None, inplace=True)

    # Substitui os 0 em amount por Null
    df["amount"].mask(df["amount"]==0, None, inplace=True)    

    # Cria coluna ano, mes e data - trava ano em 2021, mes conforme step e dia em 1
    __year=2021
    df["ano"]=__year
    df["mes"]=0  
    df["mes"]=np.where((df["step"] >= 0) & (df["step"] <= 30), 1, df["mes"])
    df["mes"]=np.where((df["step"] >= 31) & (df["step"] <= 60), 2, df["mes"])
    df["mes"]=np.where((df["step"] >= 61) & (df["step"] <= 90), 3, df["mes"])
    df["mes"]=np.where((df["step"] >= 91) & (df["step"] <= 120), 4, df["mes"])
    df["mes"]=np.where((df["step"] >= 121) & (df["step"] <= 150), 5, df["mes"])
    df["mes"]=np.where((df["step"] >= 151) & (df["step"] <= 180), 6, df["mes"])  
    __day=1
    df["data"]=__day
    df["aux1"]=None
    df["aux1"]=np.where((df["mes"] == 1), date(__year,1,__day), df["aux1"])
    df["aux1"]=np.where((df["mes"] == 2), date(__year,2,__day), df["aux1"])
    df["aux1"]=np.where((df["mes"] == 3), date(__year,3,__day), df["aux1"])
    df["aux1"]=np.where((df["mes"] == 4), date(__year,4,__day), df["aux1"])
    df["aux1"]=np.where((df["mes"] == 5), date(__year,5,__day), df["aux1"])
    df["aux1"]=np.where((df["mes"] == 6), date(__year,6,__day), df["aux1"])

def dimensional_modeling(df):
   
    # Cria 2 tabelas fato e 1 dimensão
    fact_merchant_kpi=df.groupby(["aux1", "merchant"], as_index=False).agg(tpv=('amount','sum'), qtd_transacoes=('merchant','count'))
    fact_customer_kpi=df.groupby(["aux1", "customer"], as_index=False).agg(tpv=('amount','sum'), qtd_transacoes=('customer','count'))
    dim_merchant_category=df.groupby(["merchant", "category"], as_index=False).any()[["merchant", "category"]]

    # Deleta coluna auxiliar para data
    df.drop(labels=["aux1"], inplace=True, axis=1)

    # Renomeia colunas 
    fact_merchant_kpi.rename(columns={"merchant":"id_merchant", "aux1": "data"}, inplace=True)
    fact_customer_kpi.rename(columns={"customer":"id_customer", "aux1": "data"}, inplace=True)
    dim_merchant_category.rename(columns={"merchant":"id_merchant"}, inplace=True)

    #Cria dict de criação das tabelas
    __transactions={"df": df, "table": "transactions", "schema": "db", "index": True, "index_label": "id"}
    __fact_merchant_kpi={"df": fact_merchant_kpi, "table": "fact_merchant_kpi", "schema": "analytic", "index": False, "index_label": ""}
    __fact_customer_kpi={"df": fact_customer_kpi, "table": "fact_customer_kpi", "schema": "analytic", "index": False, "index_label": ""}
    __dim_merchant_category={"df": dim_merchant_category, "table": "dim_merchant_category", "schema": "analytic", "index": False, "index_label": ""}
    
    return [__transactions, __fact_merchant_kpi, __fact_customer_kpi, __dim_merchant_category] 

def get_conn_mysql():
    __user_mysql = Variable.get("MYSQL_USER")
    __password_mysql = Variable.get("MYSQL_PASSWORD")
    __host_mysql = Variable.get("MYSQL_HOST")
    __port_mysql = Variable.get("MYSQL_PORT")
    __mysql_conn = f"mysql://{__user_mysql}:{__password_mysql}@{__host_mysql}:{__port_mysql}"
    return create_engine(__mysql_conn, echo=False)

def record_data(engine, df_dict_list):  
    for df_dict in df_dict_list:
        df_dict["df"].to_sql(
            con=engine,
            schema=df_dict["schema"],
            name=df_dict["table"],
            if_exists="replace",
            index=df_dict["index"],
            index_label=df_dict["index_label"]
        )


def tratamento_df():
    transactions_csv = criar_df()
    limpeza_dados(transactions_csv)
    df_dict_list=dimensional_modeling(transactions_csv)
    engine=get_conn_mysql()
    record_data(engine, df_dict_list)

############################################################################################################################################
with DAG("chlg_pagseguro_dag", start_date=datetime(2021, 1, 1), schedule_interval='@daily', catchup=False) as dag:
    get_data = PythonOperator(
        task_id="get_data",
        python_callable=importar_dataset
    )

    treat_data = PythonOperator(
        task_id="treat_data",
        python_callable=tratamento_df
    )

    get_data >> treat_data